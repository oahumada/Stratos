# üß† Documentaci√≥n Fase 4: Talento 360¬∞ (Gesti√≥n del Potencial con IA)

## üìã Descripci√≥n General

La Fase 4 de Stratos introduce la capacidad de evaluar no solo las habilidades actuales de los colaboradores, sino tambi√©n su **potencial latente y rasgos psicom√©tricos** mediante el uso de Agentes de IA conversacionales y un robusto modelo de feedback multi-fuente. Esta fase cierra el c√≠rculo entre la planificaci√≥n estrat√©gica y la gesti√≥n individual del talento.

---

## üß¨ Metodolog√≠a: Modelo de Evaluaci√≥n 360¬∞ en Stratos

### 1. Introducci√≥n

El modelo de evaluaci√≥n 360¬∞ desarrollado para Stratos tiene como objetivo estimar el **Nivel Actual (N)** de dominio de competencias de una persona en su rol, compar√°ndolo con un **Nivel Requerido (R)** para identificar brechas y orientar planes de desarrollo personalizados. Este enfoque integral recoge percepciones desde m√∫ltiples fuentes para reducir sesgos y obtener una visi√≥n completa del desempe√±o.

### 2. Fundamentos del Modelo

- **2.1 Enfoque 360¬∞**: La evaluaci√≥n se realiza desde diversas perspectivas: autoevaluaci√≥n, jefes, pares y subordinados. Esto permite contrastar percepciones y obtener un diagn√≥stico m√°s robusto.
- **2.2 Uso de BARS (Behaviorally Anchored Rating Scales)**: Cada competencia se define mediante una escala de 5 niveles basada en comportamientos observables y espec√≠ficos. Esto facilita que los evaluadores seleccionen el nivel que mejor describe al evaluado, asegurando claridad y objetividad.
- **2.3 Estructura de la Evaluaci√≥n**: Se utilizan 3-4 preguntas clave por competencia, cada una con 5 opciones que representan los niveles BARS. Las preguntas son consistentes para todos los evaluadores, con ajustes menores seg√∫n el rol del evaluador. Adem√°s, se recogen comentarios y evidencias cualitativas para enriquecer el an√°lisis.

### 3. C√°lculo del Nivel Actual (N)

Las respuestas se ponderan seg√∫n el rol y confiabilidad del evaluador. Se calcula un nivel representativo para cada competencia mediante medianas ponderadas, considerando la evidencia aportada y la calibraci√≥n de evaluadores. Se analizan tambi√©n la dispersi√≥n y consistencia para detectar posibles sesgos o inconsistencias.

### 4. Identificaci√≥n de Brechas (Gap)

La brecha se determina comparando el Nivel Actual (N) con el Nivel Requerido (R) definido para el rol. Esta diferencia indica √°reas de mejora y sirve para dise√±ar rutas de desarrollo personalizadas.

### 5. Tres Fuentes de la Verdad en la Evaluaci√≥n

Para garantizar una evaluaci√≥n s√≥lida y confiable, Stratos integra tres fuentes de la verdad que se complementan:

1.  **Validaci√≥n Social**: El cruce y comparaci√≥n de las evaluaciones 360¬∞ desde diferentes roles (auto, jefe, pares, subordinados), identificando consensos y discrepancias.
2.  **Evidencia**: Documentaci√≥n o ejemplos concretos que respaldan las respuestas, ajustando el peso y confiabilidad de cada evaluaci√≥n.
3.  **KPIs (Indicadores Clave de Desempe√±o)**: Datos cuantitativos relacionados con el desempe√±o real que validan o contrastan la percepci√≥n subjetiva.

### 6. Modelo H√≠brido de Generaci√≥n de Preguntas

Para garantizar relevancia y comparabilidad, Stratos utiliza un modelo h√≠brido para la generaci√≥n de preguntas:

- Existe un banco maestro de preguntas BARS predefinidas y validadas para cada competencia y arquetipo.
- La IA act√∫a como consultor senior que adapta estas preguntas al contexto espec√≠fico del escenario y proceso de negocio.
- Las preguntas generadas por IA son validadas por administradores antes de su uso en evaluaciones, asegurando consistencia y calidad.

### 7. Recomendaciones Pr√°cticas

- Dise√±ar preguntas que cubran subdimensiones clave de cada competencia y una pregunta global para validaci√≥n.
- Exigir evidencia para cada respuesta y ajustar pesos seg√∫n la calidad de la misma.
- Utilizar al menos 3 evaluadores con visibilidad directa para asegurar confiabilidad.
- Aplicar m√©todos robustos de agregaci√≥n (mediana ponderada) y an√°lisis de consistencia (ICC, dispersi√≥n).
- Implementar calibraci√≥n peri√≥dica de evaluadores para minimizar sesgos.
- Complementar con pruebas objetivas para competencias t√©cnicas cr√≠ticas.
- Mostrar indicadores de confianza y recomendaciones autom√°ticas para seguimiento.

### 8. Conclusi√≥n

El modelo 360¬∞ de Stratos ofrece una metodolog√≠a estructurada, flexible y robusta para evaluar competencias y detectar brechas de manera precisa. Su enfoque h√≠brido en la generaci√≥n de preguntas garantiza relevancia contextual sin sacrificar la comparabilidad, facilitando la toma de decisiones informadas para el desarrollo del talento y la planificaci√≥n estrat√©gica.

---

## üèóÔ∏è Componentes T√©cnicos

### 1. Modelado de Datos (Laravel)

Se han implementado tres tablas principales para gestionar el ciclo de vida de las evaluaciones:

- **`competency_levels_bars`**: Definiciones de los 5 niveles de comportamiento para cada habilidad (BARS).
- **`skill_question_bank`**: Banco de preguntas maestr√≠as por habilidad y arquetipo.
- **`assessment_sessions`**: Registro de la sesi√≥n de entrevista (tipo, estado, metadatos de potencial).
- **`assessment_messages`**: Registro hist√≥rico (log) de la conversaci√≥n entre el humano y el agente de IA.
- **`psychometric_profiles`**: Resultados estructurados del an√°lisis (Rasgo, Puntaje, Justificaci√≥n).
- **`assessment_requests`**: Gesti√≥n de solicitudes de feedback a terceros (evaluador, sujeto, relaci√≥n, token).
- **`assessment_feedback`**: Almacenamiento de respuestas cualitativas y puntajes BARS (score, evidence, confidence).

**Modelos:**

- `AssessmentSession`, `AssessmentMessage`, `PsychometricProfile`.

### 2. Microservicio de Inteligencia (Python / FastAPI)

Se han a√±adido dos agentes especializados utilizando **CrewAI** y **DeepSeek**:

- **Expert Psychometric Interviewer**: Conduce la entrevista de forma din√°mica, realizando preguntas de seguimiento basadas en las respuestas del usuario para profundizar en rasgos de personalidad.
- **Talent Assessment Analyst**: Procesa la transcripci√≥n completa para extraer un perfil JSON con puntajes de 0 a 1 y un reporte sumario.

**Endpoints:**

- `POST /interview/chat`: Genera la siguiente respuesta del entrevistador AI.
- `POST /interview/analyze`: Realiza el cierre y an√°lisis psicom√©trico binario (Sujeto/IA).
- `POST /interview/analyze-360`: Orquestador de la **Triangulaci√≥n de la Verdad**, analizando la entrevista vs. feedback externo para detectar discrepancias.

### 3. Servicios e Integraci√≥n (Laravel)

- **`StratosAssessmentService`**: Orquestador de la comunicaci√≥n entre PHP y el microservicio de IA. Soporta ahora `analyzeThreeSixty`.
- **`AssessmentController`**: Expone la API para el frontend, gestionando la persistencia de mensajes, la solicitud de feedback a terceros y la sumisi√≥n de respuestas.
- **`Talento360Controller`**: Genera m√©tricas agregadas para el dashboard organizacional.

---

## üîç Triangulaci√≥n y Puntos Ciegos (Blind Spots)

El sistema ya no depende √∫nicamente de lo que el colaborador dice. Stratos ahora implementa un modelo de **Triangulaci√≥n de la Verdad**:

1.  **Auto-percepci√≥n**: Obtenida mediante la entrevista psicom√©trica AI.
2.  **Percepci√≥n Externa**: Feedback cualitativo de pares, supervisores y subordinados.
3.  **An√°lisis de IA**: El agente "Expert Talent Analyst" cruza ambas fuentes para identificar:
    - **Fortalezas Validadas**: Donde ambas percepciones coinciden.
    - **Puntos Ciegos**: Rasgos positivos vistos por otros pero no por el sujeto, o debilidades no reconocidas.
    - **Gaps de Credibilidad**: Discrepancias significativas en el nivel de maestr√≠a t√©cnica o conductual.

## üîÆ Metodolog√≠a BARS (Behaviorally Anchored Rating Scales)

La gesti√≥n del feedback se ha profesionalizado mediante un modelo de "Escalas de Comportamiento":

### 1. Estructura de Captura

- **Feedback Estructurado**: Ya no son solo opiniones abiertas. Utilizamos el modelo BARS para calificar habilidades en una escala del 1 al 5, donde cada nivel tiene una descripci√≥n conductual precisa.
- **Evidencia Obligatoria**: Para puntajes extremos (1 o 5), el sistema exige un link o justificaci√≥n de evidencia (URL, Jira, Documento), garantizando objetividad.
- **Nivel de Confianza (Confidence Score)**: Cada evaluador indica qu√© tan seguro est√° de su calificaci√≥n (0-100%).

### 2. Motor de C√°lculo (`CompetencyAssessmentService`)

El c√°lculo del "Nivel Actual" de una competencia no es un promedio simple. Stratos aplica:

- **Ponderaci√≥n por Rol**: Jefe (40%) > Pares (30%) > Subordinados (20%) > Auto (10%).
- ** Ajuste de Confianza**: Las calificaciones con baja confianza (investigador incierto) pesan menos en el resultado final.
- **An√°lisis de Dispersi√≥n (SD)**: Si la Desviaci√≥n Est√°ndar entre evaluadores supera `1.5`, el sistema marca la habilidad como **"Requiere Calibraci√≥n"** (verified = false).

### 3. Integraci√≥n de KPIs de Negocio (`PerformanceDataService`)

Para aterrizar el "Potencial" a la "Realidad", el sistema inyecta datos duros de desempe√±o en el an√°lisis de IA:

- **Ventas / Objetivos**: Cumplimiento % trimestral.
- **NPS / Calidad**: M√©tricas de satisfacci√≥n del cliente.
- **Velocidad**: M√©tricas de entrega de proyectos.

Esta triangulaci√≥n (Psicometr√≠a + Feedback 360¬∞ + KPIs) permite detectar:

- **High Potentials Reales**: Alto potencial + Alto desempe√±o.
- **Underachievers**: Alto potencial + Bajo desempe√±o (Problema motivacional o de entorno).
- **Overachievers**: Bajo potencial + Alto desempe√±o (Riesgo de burnout o techo t√©cnico).

---

## üíª Interfaz de Usuario (Vue 3 + Vuetify)

### üí¨ Chat de Evaluaci√≥n (`AssessmentChat.vue`)

... (contenido previo) ...

### üõ°Ô∏è Gesti√≥n de Feedback (`PendingFeedback.vue`)

Integrado en el Dashboard principal, este componente alerta proactivamente al colaborador sobre solicitudes de feedback pendientes.

- **Selecci√≥n Inteligente**: Al abrir un request, el sistema ya pre-seleccion√≥ las preguntas BARS relevantes para las habilidades del sujeto y la relaci√≥n con el evaluador.
- **`FeedbackFormBARS.vue`**: Componente visual interactivo para calificaci√≥n conductual.

---

## ‚úÖ Validaci√≥n y Calidad

- **Tests Unitarios/Feature**: `tests/Feature/Api/AssessmentApiTest.php` valida:
    - Flujo de entrevista.
    - Captura de feedback 360¬∞.
    - **C√°lculo autom√°tico de niveles de competencia** tras el an√°lisis.
- **Agnosticismo**: Compatible con DeepSeek, Abacus o OpenAI.

---

## üõ†Ô∏è C√≥mo Iniciar una Evaluaci√≥n

1. Navegar a **People**.
2. Seleccionar un colaborador.
3. Ir a la pesta√±a **Potencial AI**.
4. Hacer clic en **"Comenzar Entrevista"**.
5. Al finalizar, hacer clic en **"Finalizar y Analizar"**.
6. (Autom√°tico) El sistema solicita feedback 360 a pares predefinidos.
7. Al completarse el feedback, se actualiza el perfil de competencias.
